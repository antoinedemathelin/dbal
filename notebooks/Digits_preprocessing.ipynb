{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Conv2D, MaxPooling2D, Flatten, Reshape, GaussianNoise\n",
    "from tensorflow.keras.constraints import MinMaxNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download synth and svhn datasets:\n",
    "- synth: http://yaroslav.ganin.net/ (SynNumbers)\n",
    "- svhn: http://ufldl.stanford.edu/housenumbers/\n",
    "\n",
    "Extract then the train part of the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_digits = \"../datasets/digits/\"\n",
    "\n",
    "Xs = np.load(path_to_digits + \"synth_X.npy\")\n",
    "ys = np.load(path_to_digits + \"synth_y.npy\")\n",
    "\n",
    "Xt = np.load(path_to_digits + \"svhn_X.npy\")\n",
    "yt = np.load(path_to_digits + \"svhn_y.npy\")\n",
    "\n",
    "one = OneHotEncoder(sparse=False)\n",
    "ys_cat = one.fit_transform(ys.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    modeled = Conv2D(32, 5, activation='relu')(inputs)\n",
    "    modeled = MaxPooling2D(2, 2)(modeled)\n",
    "    modeled = Conv2D(48, 5, activation='relu')(modeled)\n",
    "    modeled = MaxPooling2D(2, 2)(modeled)\n",
    "    modeled = Flatten()(modeled)\n",
    "    model = Model(inputs, modeled)\n",
    "    model.compile(optimizer=\"adam\", loss='mse')\n",
    "    return model\n",
    "\n",
    "def get_task(input_shape, output_shape=(10,), activation=\"softmax\", C=1.):\n",
    "    inputs = Input(input_shape)\n",
    "    modeled = Dense(100, activation='relu',\n",
    "                         kernel_constraint=MinMaxNorm(0, C),\n",
    "                         bias_constraint=MinMaxNorm(0, C))(inputs)\n",
    "    modeled = Dense(100, activation='relu',\n",
    "                         kernel_constraint=MinMaxNorm(0, C),\n",
    "                         bias_constraint=MinMaxNorm(0, C))(modeled)\n",
    "    modeled = Dense(np.prod(output_shape), activation=activation)(modeled)\n",
    "    model = Model(inputs, modeled)\n",
    "    model.compile(optimizer=\"adam\", loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator(input_shape, C=1.):\n",
    "    inputs = Input(input_shape)\n",
    "    modeled = Dense(100, activation='relu',\n",
    "                         kernel_constraint=MinMaxNorm(0, C),\n",
    "                         bias_constraint=MinMaxNorm(0, C))(inputs)\n",
    "    modeled = Dense(100, activation='relu',\n",
    "                         kernel_constraint=MinMaxNorm(0, C),\n",
    "                         bias_constraint=MinMaxNorm(0, C))(modeled)\n",
    "    modeled = Dense(1, activation=\"sigmoid\")(modeled)\n",
    "    model = Model(inputs, modeled)\n",
    "    model.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "model (Model)                (None, 768)               39280     \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 10)                88010     \n",
      "=================================================================\n",
      "Total params: 127,290\n",
      "Trainable params: 127,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input((28, 28, 1))\n",
    "encoder = get_encoder((28, 28, 1))\n",
    "task = get_task(encoder.output_shape[1:])\n",
    "\n",
    "encoded = encoder(inputs)\n",
    "tasked = task(encoded)\n",
    "\n",
    "model = Model(inputs, tasked)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(0.001), metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 32s 539us/sample - loss: 0.6494 - accuracy: 0.7950\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 33s 543us/sample - loss: 0.2502 - accuracy: 0.9250\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 32s 528us/sample - loss: 0.1808 - accuracy: 0.9449\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 33s 542us/sample - loss: 0.1409 - accuracy: 0.9566\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 32s 537us/sample - loss: 0.1168 - accuracy: 0.9636\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 31s 524us/sample - loss: 0.0975 - accuracy: 0.9696\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 32s 530us/sample - loss: 0.0889 - accuracy: 0.9720\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 31s 518us/sample - loss: 0.0778 - accuracy: 0.9752\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 31s 521us/sample - loss: 0.0728 - accuracy: 0.9768\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 31s 518us/sample - loss: 0.0653 - accuracy: 0.9798\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 31s 513us/sample - loss: 0.0583 - accuracy: 0.9811\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 31s 516us/sample - loss: 0.0553 - accuracy: 0.9820\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 31s 514us/sample - loss: 0.0480 - accuracy: 0.9848\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 31s 520us/sample - loss: 0.0475 - accuracy: 0.9846\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 31s 514us/sample - loss: 0.0491 - accuracy: 0.9844\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 31s 518us/sample - loss: 0.0436 - accuracy: 0.9860\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 31s 510us/sample - loss: 0.0435 - accuracy: 0.9858\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 31s 513us/sample - loss: 0.0389 - accuracy: 0.9877\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 31s 514us/sample - loss: 0.0366 - accuracy: 0.9883\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 31s 514us/sample - loss: 0.0378 - accuracy: 0.9878\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 31s 515us/sample - loss: 0.0331 - accuracy: 0.9894\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 31s 519us/sample - loss: 0.0331 - accuracy: 0.9893\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 31s 521us/sample - loss: 0.0321 - accuracy: 0.9899\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 31s 515us/sample - loss: 0.0337 - accuracy: 0.9891\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 31s 515us/sample - loss: 0.0317 - accuracy: 0.9901\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 31s 514us/sample - loss: 0.0275 - accuracy: 0.9912\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.98 - 31s 520us/sample - loss: 0.0320 - accuracy: 0.9898\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 31s 515us/sample - loss: 0.0300 - accuracy: 0.9908\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 31s 515us/sample - loss: 0.0267 - accuracy: 0.9911\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 31s 518us/sample - loss: 0.0240 - accuracy: 0.9923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x267804fce88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "model.fit(Xs[:,:,:,np.newaxis], ys_cat, batch_size=128, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((Xs, Xt))\n",
    "y_lab = np.concatenate((np.zeros(len(Xs)), np.ones(len(Xt))))\n",
    "\n",
    "X = encoder.predict(X[:,:,:,np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 133257 samples\n",
      "Epoch 1/10\n",
      "133257/133257 [==============================] - 4s 26us/sample - loss: 0.1780 - accuracy: 0.9314\n",
      "Epoch 2/10\n",
      "133257/133257 [==============================] - 4s 31us/sample - loss: 0.1320 - accuracy: 0.9507\n",
      "Epoch 3/10\n",
      "133257/133257 [==============================] - 4s 27us/sample - loss: 0.1209 - accuracy: 0.9552\n",
      "Epoch 4/10\n",
      "133257/133257 [==============================] - 4s 31us/sample - loss: 0.1154 - accuracy: 0.9574\n",
      "Epoch 5/10\n",
      "133257/133257 [==============================] - 4s 32us/sample - loss: 0.1121 - accuracy: 0.9587\n",
      "Epoch 6/10\n",
      "133257/133257 [==============================] - 3s 26us/sample - loss: 0.1084 - accuracy: 0.9598\n",
      "Epoch 7/10\n",
      "133257/133257 [==============================] - 5s 36us/sample - loss: 0.1055 - accuracy: 0.9605\n",
      "Epoch 8/10\n",
      "133257/133257 [==============================] - 3s 23us/sample - loss: 0.1062 - accuracy: 0.9604\n",
      "Epoch 9/10\n",
      "133257/133257 [==============================] - 5s 39us/sample - loss: 0.1046 - accuracy: 0.9613\n",
      "Epoch 10/10\n",
      "133257/133257 [==============================] - 3s 26us/sample - loss: 0.1020 - accuracy: 0.9620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22e69761508>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = get_discriminator(X.shape[1:])\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "discriminator.fit(X, y_lab, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_models = \"../datasets/models_digits/\"\n",
    "\n",
    "encoder.save(path_to_models + \"encoder.h5\")\n",
    "task.save(path_to_models + \"task.h5\")\n",
    "discriminator.save(path_to_models + \"discriminator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapt.feature_based import DANN\n",
    "\n",
    "dann = DANN(get_encoder=get_encoder, get_task=get_task, get_discriminator=get_discriminator,\n",
    "           lambdap=0.1, loss=\"categorical_crossentropy\", optimizer=Adam(0.001), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((Xs, Xt))\n",
    "y = np.concatenate((ys, yt))\n",
    "\n",
    "src_index = np.array(range(len(Xs)))\n",
    "tgt_index = np.array(range(len(Xs), len(X)))\n",
    "\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 133257 samples\n",
      "Epoch 1/30\n",
      "133257/133257 [==============================] - 151s 1ms/sample - loss: 0.9316 - model_1_loss: 0.6841 - model_2_loss: 0.4946 - model_1_accuracy: 0.7781 - model_2_accuracy: 0.8099\n",
      "Epoch 2/30\n",
      "133257/133257 [==============================] - 143s 1ms/sample - loss: 0.5439 - model_1_loss: 0.3730 - model_2_loss: 0.3409 - model_1_accuracy: 0.8841 - model_2_accuracy: 0.8636s - loss: 0.5488 - model_1_loss: 0.3770 - model_2_loss: 0.3436 - model_1_accuracy: 0.8829 - model_2_accurac - ETA: 3s - loss: 0.5473 - model_1_loss: 0.3759 - model_2_loss: 0.3427 - model_1_accuracy: 0.8832 - \n",
      "Epoch 3/30\n",
      "133257/133257 [==============================] - 155s 1ms/sample - loss: 0.3619 - model_1_loss: 0.2378 - model_2_loss: 0.2479 - model_1_accuracy: 0.9255 - model_2_accuracy: 0.9038\n",
      "Epoch 4/30\n",
      "133257/133257 [==============================] - 145s 1ms/sample - loss: 0.2915 - model_1_loss: 0.1822 - model_2_loss: 0.2182 - model_1_accuracy: 0.9431 - model_2_accuracy: 0.9153\n",
      "Epoch 5/30\n",
      "133257/133257 [==============================] - 168s 1ms/sample - loss: 0.2557 - model_1_loss: 0.1518 - model_2_loss: 0.2082 - model_1_accuracy: 0.9524 - model_2_accuracy: 0.9186\n",
      "Epoch 6/30\n",
      "133257/133257 [==============================] - 141s 1ms/sample - loss: 0.2259 - model_1_loss: 0.1273 - model_2_loss: 0.1974 - model_1_accuracy: 0.9596 - model_2_accuracy: 0.9230\n",
      "Epoch 7/30\n",
      "133257/133257 [==============================] - 140s 1ms/sample - loss: 0.2128 - model_1_loss: 0.1131 - model_2_loss: 0.1992 - model_1_accuracy: 0.9640 - model_2_accuracy: 0.92252s - loss: 0.2136 - model_1_loss: 0.11 - ETA: 4s - loss: 0.2135 - model_1_loss: 0.1136 - model_2_loss: 0.1996 - model_1_accuracy:\n",
      "Epoch 8/30\n",
      "133257/133257 [==============================] - 140s 1ms/sample - loss: 0.1956 - model_1_loss: 0.0974 - model_2_loss: 0.1967 - model_1_accuracy: 0.9692 - model_2_accuracy: 0.9235s - loss: 0.1950 - model_1_loss: 0.0969 - model_2_loss: 0.1960 - mode\n",
      "Epoch 9/30\n",
      "133257/133257 [==============================] - 140s 1ms/sample - loss: 0.1841 - model_1_loss: 0.0866 - model_2_loss: 0.1951 - model_1_accuracy: 0.9724 - model_2_accuracy: 0.9243\n",
      "Epoch 10/30\n",
      "133257/133257 [==============================] - 140s 1ms/sample - loss: 0.1781 - model_1_loss: 0.0784 - model_2_loss: 0.1992 - model_1_accuracy: 0.9750 - model_2_accuracy: 0.9220\n",
      "Epoch 11/30\n",
      "133257/133257 [==============================] - 143s 1ms/sample - loss: 0.1734 - model_1_loss: 0.0729 - model_2_loss: 0.2007 - model_1_accuracy: 0.9764 - model_2_accuracy: 0.9206s - loss: 0.1733 - model_1_loss: 0.0731 - model_2_loss: 0.2005 - model_1_accuracy: 0.9764 \n",
      "Epoch 12/30\n",
      "133257/133257 [==============================] - 142s 1ms/sample - loss: 0.1716 - model_1_loss: 0.0690 - model_2_loss: 0.2051 - model_1_accuracy: 0.9778 - model_2_accuracy: 0.9193\n",
      "Epoch 13/30\n",
      "133257/133257 [==============================] - 141s 1ms/sample - loss: 0.1633 - model_1_loss: 0.0634 - model_2_loss: 0.1995 - model_1_accuracy: 0.9794 - model_2_accuracy: 0.9217\n",
      "Epoch 14/30\n",
      "133257/133257 [==============================] - 139s 1ms/sample - loss: 0.1581 - model_1_loss: 0.0580 - model_2_loss: 0.2001 - model_1_accuracy: 0.9812 - model_2_accuracy: 0.9217\n",
      "Epoch 15/30\n",
      "133257/133257 [==============================] - 142s 1ms/sample - loss: 0.1587 - model_1_loss: 0.0564 - model_2_loss: 0.2044 - model_1_accuracy: 0.9816 - model_2_accuracy: 0.9188\n",
      "Epoch 16/30\n",
      "133257/133257 [==============================] - 144s 1ms/sample - loss: 0.1571 - model_1_loss: 0.0524 - model_2_loss: 0.2092 - model_1_accuracy: 0.9831 - model_2_accuracy: 0.9173\n",
      "Epoch 17/30\n",
      "133257/133257 [==============================] - 141s 1ms/sample - loss: 0.1579 - model_1_loss: 0.0521 - model_2_loss: 0.2113 - model_1_accuracy: 0.9828 - model_2_accuracy: 0.9163\n",
      "Epoch 18/30\n",
      "133257/133257 [==============================] - 142s 1ms/sample - loss: 0.1555 - model_1_loss: 0.0487 - model_2_loss: 0.2136 - model_1_accuracy: 0.9843 - model_2_accuracy: 0.9161\n",
      "Epoch 19/30\n",
      "133257/133257 [==============================] - 142s 1ms/sample - loss: 0.1577 - model_1_loss: 0.0490 - model_2_loss: 0.2172 - model_1_accuracy: 0.9839 - model_2_accuracy: 0.91369s  - ETA: 11s - loss: 0.1562 - model_1_loss: 0.0485 - model_2_loss: 0.2154 - mo - ETA: 6s - loss: 0.1569 - model_1_loss: 0.0486 - model_2_loss: 0.2165 - \n",
      "Epoch 20/30\n",
      "133257/133257 [==============================] - 142s 1ms/sample - loss: 0.1592 - model_1_loss: 0.0475 - model_2_loss: 0.2233 - model_1_accuracy: 0.9844 - model_2_accuracy: 0.9113\n",
      "Epoch 21/30\n",
      "133257/133257 [==============================] - 142s 1ms/sample - loss: 0.1609 - model_1_loss: 0.0488 - model_2_loss: 0.2253 - model_1_accuracy: 0.9842 - model_2_accuracy: 0.9102\n",
      "Epoch 22/30\n",
      "133257/133257 [==============================] - 144s 1ms/sample - loss: 0.1606 - model_1_loss: 0.0467 - model_2_loss: 0.2279 - model_1_accuracy: 0.9848 - model_2_accuracy: 0.9087s - loss: 0.1607 - model_1_loss: 0.0467 - model_2_loss: 0.227\n",
      "Epoch 23/30\n",
      "133257/133257 [==============================] - 143s 1ms/sample - loss: 0.1612 - model_1_loss: 0.0454 - model_2_loss: 0.2315 - model_1_accuracy: 0.9853 - model_2_accuracy: 0.90748s - loss: 0.1608 - m\n",
      "Epoch 24/30\n",
      "133257/133257 [==============================] - 143s 1ms/sample - loss: 0.1634 - model_1_loss: 0.0453 - model_2_loss: 0.2361 - model_1_accuracy: 0.9854 - model_2_accuracy: 0.9040\n",
      "Epoch 25/30\n",
      "133257/133257 [==============================] - 140s 1ms/sample - loss: 0.1660 - model_1_loss: 0.0467 - model_2_loss: 0.2387 - model_1_accuracy: 0.9847 - model_2_accuracy: 0.9033\n",
      "Epoch 26/30\n",
      "133257/133257 [==============================] - 143s 1ms/sample - loss: 0.1660 - model_1_loss: 0.0451 - model_2_loss: 0.2418 - model_1_accuracy: 0.9855 - model_2_accuracy: 0.9010\n",
      "Epoch 27/30\n",
      "133257/133257 [==============================] - 141s 1ms/sample - loss: 0.1645 - model_1_loss: 0.0426 - model_2_loss: 0.2437 - model_1_accuracy: 0.9865 - model_2_accuracy: 0.9011\n",
      "Epoch 28/30\n",
      "133257/133257 [==============================] - 139s 1ms/sample - loss: 0.1680 - model_1_loss: 0.0435 - model_2_loss: 0.2487 - model_1_accuracy: 0.9858 - model_2_accuracy: 0.8991\n",
      "Epoch 29/30\n",
      "133257/133257 [==============================] - 139s 1ms/sample - loss: 0.1670 - model_1_loss: 0.0428 - model_2_loss: 0.2482 - model_1_accuracy: 0.9860 - model_2_accuracy: 0.8988s - loss: 0.1663 - model_1_loss: 0.0426 - model_2_loss: 0.2474 - model_1_accuracy: 0.9860 \n",
      "Epoch 30/30\n",
      "133257/133257 [==============================] - 140s 1ms/sample - loss: 0.1697 - model_1_loss: 0.0435 - model_2_loss: 0.2524 - model_1_accuracy: 0.9861 - model_2_accuracy: 0.8959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<adapt.feature_based._dann.DANN at 0x2418cd7fc48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "dann.fit(X, y, src_index, tgt_index, batch_size=128, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_models = \"../datasets/models_digits/\"\n",
    "\n",
    "dann.encoder_.save(path_to_models + \"dann_encoder.h5\")\n",
    "dann.task_.save(path_to_models + \"dann_task.h5\")\n",
    "dann.discriminator_.save(path_to_models + \"dann_discriminator.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (statmath)",
   "language": "python",
   "name": "statmath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
